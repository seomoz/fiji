#!/usr/bin/env python3
# -*- coding: utf-8; mode: python -*-

"""Workflow tasks for fiji-build."""

import base64
import itertools
import logging
import os
import pickle
import re
import shutil
import tarfile
import tempfile
import time
import venv

from base import base
from base import command
from base import log
from base import record

from wibi.build import build_defs
from wibi.build import build_tools
from wibi.build import java_linker
from wibi.maven import artifact
from workflow import workflow


# Artifact coordinate use to exclude any/all artifacts:
ANY_ARTIFACT_NAME = artifact.ArtifactName(group_id="*", artifact_id="*")


RULER = ("-" * 100)
NL_RULER_NL = ("\n" + RULER + "\n")


# --------------------------------------------------------------------------------------------------


class Error(Exception):
    """Errors used in this module."""
    pass


# --------------------------------------------------------------------------------------------------


def indent_line(line):
    """Indent the specified text line with a left tab.

    Args:
        line: Single line of text to indent.
    Returns:
        The indented line.
    """
    return "\t" + line


class Lazy(object):
    """Wraps a formatting rule into a lazy closure, for logging purposes.

    Usage:
        log.info("Formatting {}", lazy(lambda: ... complex formatting goes here ...))
    """

    def __init__(self, fn):
        """Creates a new lazy-formatting wrapper.

        Args:
            fn: 0-parameter lambda that returns a string to display.
        """
        self._fn = fn

    def __format__(self, spec):
        assert (len(spec) == 0), "Unexpected format spec: {!r}".format(spec)
        return self._fn()


# Shortcut:
lazy = Lazy


def format_command_output(cmd):
    """Formats the output of a Command.

    Skip over the test annotation processor output.
    Output and error streams are delimited by horizontal rulers.

    Args:
        cmd: Command whose output is to be formatted.
    Returns:
        The formatted command output and error streams.
    """
    content = []
    error = cmd.error_text.strip()
    error = "\n".join(filter(lambda line: not line.startswith("TestAnnotationCollector: "),
                             error.split("\n")))
    if len(error) > 0:
        content.append(error)
    output = cmd.output_text.strip()
    output = "\n".join(filter(lambda line: not line.startswith("TestAnnotationCollector: "),
                              output.split("\n")))
    if len(output) > 0:
        content.append(output)

    if len(content) == 0:
        return ""

    return NL_RULER_NL + NL_RULER_NL.join(content) + ("\n" + RULER)


# --------------------------------------------------------------------------------------------------


class WorkspaceTask(workflow.IOTask):
    """Abstract base class for tasks running in a workspace."""

    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec=None,
        force=False,
    ):
        self._workspace = workspace
        self._name = name
        self._spec = spec

        super().__init__(
            task_id=self.make_task_id(),
            workflow=workflow,
            ignore_saved_output_trace=force,
            write_output_trace=True,
        )

    @property
    def workspace(self):
        """Returns: the Workspace of the project to operate on."""
        return self._workspace

    @property
    def name(self):
        """Returns: the name of this task."""
        return self._name

    @property
    def tools(self):
        """Returns: the build tools to use."""
        return self.workspace.tools

    @property
    def spec(self):
        return self._spec

    def make_task_id(self):
        return self.name

    def should_task_run(self, task_run_id, output, **inputs):
        """Determines whether the workspace task should re-run or is already up-to-date.

        Args:
            task_run_id: ID of the task run to evaluate.
            output: Output record generated by a previous run of this task.
            **inputs: Map of the output records for the dependency tasks.
        Returns:
            True if this task must re-run, false if can be omitted.
        """
        output_fingerprint = getattr(self, "output_fingerprint", None)

        if output_fingerprint is None:
            logging.debug("No output fingeprint for task %r : forcing re-run.", self.task_id)
            return True

        if output.output_fingerprint != output_fingerprint:
            logging.debug("Forcing re-run for task %r, output fingerprint mismatch: "
                          "effective output %r != expected output %r.",
                          self.task_id, output_fingerprint, output.output_fingerprint)
            return True

        logging.debug("Output fingerprint match for task %r (%r): Skipping task run.",
                      self.task_id, output_fingerprint)
        return False

    def _get_trace_file_path(self, task_run_id):
        return os.path.join(self.workspace.temp_dir, "workflow", base.make_ident(task_run_id))

    def run(self):
        def str_complete_task_state(task_state):
            if task_state == workflow.TaskState.FAILURE:
                return "Failed"
            elif task_state == workflow.TaskState.SUCCESS:
                return "Completed"
            elif task_state == workflow.TaskState.ALREADY_DONE:
                return "Skipped"
            else:
                raise Error("task_state {!r} is neither a success or failure.".format(task_state))

        logging.info("%10s %r", "Processing", self.name)
        start_time = time.time()
        result = workflow.TaskState.FAILURE
        try:
            result = super().run()
            return result
        except:
            logging.error("Failure for %r", self.name)
            raise
        finally:
            end_time = time.time()
            logging.info(
                "%10s %r in %.3fs",
                str_complete_task_state(result),
                self.name,
                end_time - start_time,
            )

    # ----------------------------------------------------------------------------------------------
    # Utilities for sub-classes:

    def get_source_map(self, sources):
        """Reports the source map for the specified source specification.

        Args:
            sources: Collection of source selector specifications.
        Returns:
            Map: path relative to the source root -> workspace-relative path.
        """
        paths = dict()
        for source in sources:
            aroot = self.workspace.apath(source.root)
            pattern = os.path.join(aroot, source.selector)
            for apath in build_tools.extglob(pattern):
                source_path = os.path.relpath(apath, aroot)
                wpath = self.workspace.wpath(apath)
                assert (source_path not in paths), "Duplicate source path {}".format(source_path)
                paths[source_path] = wpath
        return paths

    def merge_source_maps(self, maps):
        """Merges a collection of source maps.

        Args:
            maps: Collection of source map to merge.
        Returns:
            Merged source map: path relative to the source root -> workspace-relative path.
        """
        merged = dict()
        for source_path, wpath in itertools.chain(*map(dict.items, maps)):
            existing = merged.get(source_path)
            if (existing is not None) and (existing != wpath):
                with open(self.tools.resolve_wpath(existing), mode="rt", encoding="utf-8") as f:
                    existing_content = f.read()
                with open(self.tools.resolve_wpath(wpath), mode="rt", encoding="utf-8") as f:
                    wpath_content = f.read()
                if existing_content != wpath_content:
                    raise Error("Conflicting source entry {} : {} vs {}"
                                .format(source_path, existing, wpath))
            merged[source_path] = wpath
        return merged

    def printable_test_log_path(self, log_path, log_path_prefix):
        """Generates a printable test log path from a base log path and options.

        Args:
            log_path: A path to a log file.
            log_path_prefix: If not None, prepend this string to the path.
        Returns:
            A printable test log path.
        """
        if log_path_prefix is not None:
            log_path = os.path.join(log_path_prefix, log_path)
        return log_path


# --------------------------------------------------------------------------------------------------


class WorkspaceTaskForArtifact(WorkspaceTask):
    """Workspace task emitting a Maven artifact (inferred from the task name).

    Task specification may include an explicit 'library_name' that overrides the task's name.
    """

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        library_name = self.name
        if self.spec.library_name not in (base.UNDEFINED, None):
            library_name = self.spec.library_name

        aname = artifact_from_name(library_name)

        version = self.workspace.config.maven_artifact_version
        if self.spec.version not in (base.UNDEFINED, None):
            version = self.spec.version

        self._artifact = artifact.Artifact(
            group_id=aname.group_id,
            artifact_id=aname.artifact_id,
            version=version,
        )

    @property
    def artifact(self):
        return self._artifact


# --------------------------------------------------------------------------------------------------


def name_from_artifact(artf):
    return "//%s:%s" % (artf.group_id.replace(".", "/"), artf.artifact_id)


def artifact_from_name(name):
    name = base.strip_prefix(name, "//")
    (group, aid) = name.split(":")
    group = group.replace("/", ".")
    return artifact.ArtifactName(group, aid)


# --------------------------------------------------------------------------------------------------


POM_XML_TEMPLATE = """\
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>{group_id}</groupId>
  <artifactId>{artifact_id}</artifactId>
  <version>{version}</version>
  <packaging>{packaging}</packaging>

  <name>Fiji</name>
  <description>Fiji allows the imposition of schema and much else upon HBase.</description>
  <url>https://github.com/seomoz/fiji</url>

  <licenses>
    <license>
      <name>The Apache License, Version 2.0</name>
      <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>
    </license>
  </licenses>

  <developers>
    <developer>
      <id>sistawendy</id>
      <name>Maura Hubbell</name>
      <email>maura@moz.com</email>
    </developer>
    <developer>
      <id>phs</id>
      <name>Phil Smith</name>
      <email>phil.h.smith@gmail.com</email>
    </developer>
    <developer>
      <id>b4hand</id>
      <name>Brandon Forehand</name>
      <email>brandon@moz.com</email>
    </developer>
    <developer>
      <id>Pyrinoc</id>
      <name>Don Conley</name>
      <email>don@moz.com</email>
    </developer>
    <developer>
      <id>dlecocq</id>
      <name>Dan Lecocq</name>
      <email>dan@moz.com</email>
    </developer>
  </developers>

  <properties>
{properties}
  </properties>

  <scm>
    <connection>scm:git:git@github.com:seomoz/fiji.git</connection>
    <developerConnection>scm:git:git@github.com:seomoz/fiji.git</developerConnection>
    <url>git@github.com:seomoz/fiji.git</url>
  </scm>

  <!-- https://github.com/making/travis-ci-maven-deploy-skelton -->
  <profiles>
    <profile>
      <id>ossrh</id>
      <properties>
        <gpg.executable>gpg</gpg.executable>
        <gpg.keyname>${{env.GPG_KEYNAME}}</gpg.keyname>
        <gpg.passphrase>${{env.GPG_PASSPHRASE}}</gpg.passphrase>
        <gpg.defaultKeyring>false</gpg.defaultKeyring>
        <gpg.publicKeyring>${{env.TRAVIS_BUILD_DIR}}/devtools/pubring.gpg</gpg.publicKeyring>
        <gpg.secretKeyring>${{env.TRAVIS_BUILD_DIR}}/devtools/secring.gpg</gpg.secretKeyring>
      </properties>
      <activation>
        <property>
          <name>performRelease</name>
          <value>true</value>
        </property>
      </activation>
      <build>
        <plugins>
          <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-gpg-plugin</artifactId>
            <version>1.5</version>
            <executions>
              <execution>
                <id>sign-artifacts</id>
                <phase>verify</phase>
                <goals>
                  <goal>sign</goal>
                </goals>
              </execution>
            </executions>
          </plugin>
          <plugin>
            <groupId>org.sonatype.plugins</groupId>
            <artifactId>nexus-staging-maven-plugin</artifactId>
            <version>1.6.2</version>
            <extensions>true</extensions>
            <configuration>
              <serverId>ossrh</serverId>
              <nexusUrl>https://oss.sonatype.org/</nexusUrl>
              <autoReleaseAfterClose>true</autoReleaseAfterClose>
            </configuration>
          </plugin>
        </plugins>
      </build>
    </profile>
  </profiles>

  <repositories>
    <repository>
      <id>central</id>
      <name>Maven Central</name>
      <url>http://repo1.maven.org/maven2/</url>
    </repository>
    <repository>
      <id>cloudera-repo</id>
      <name>Cloudera CDH</name>
      <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
    </repository>
  </repositories>

  <distributionManagement>
    <snapshotRepository>
      <id>ossrh</id>
      <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    </snapshotRepository>
    <repository>
      <id>ossrh</id>
      <url>https://oss.sonatype.org/service/local/staging/deploy/maven2/</url>
    </repository>
  </distributionManagement>

  <!-- Unresolved dependency list: -->
{unresolved_deps}
{fiji_build_exclusions}

  <!-- Resolved dependency list: -->
  <dependencies>
{dependencies}
  </dependencies>

</project>
"""

MAVEN_DEP = (
    "<dependency> "
        "{group_id:60s} "
        "{artifact_id:60s} "
        "{type:30s} "
        "{classifier}"
        "{version:40s} "
        "<scope>{scope}</scope> "
        "{exclusions}"
    "</dependency>"
)

MAVEN_EXCLUSIONS = "<exclusions> {exclusions} </exclusions>"
MAVEN_EXCLUSION = \
    "<exclusion><groupId>{group_id}</groupId><artifactId>{artifact_id}</artifactId></exclusion>"


def element(name, value):
    return "<{name}>{value}</{name}>".format(name=name, value=value)


def format_pom_file(
    artf,
    compile_deps,
    test_deps=tuple(),
    exclusions=frozenset(),
    pom_template=POM_XML_TEMPLATE,
    unresolved_deps=tuple(),
    fiji_build_exclusions=tuple(),
    java_target_version="1.8",
    java_source_version="1.8",
):
    """Formats the content of a pom.xml descriptor for the specified Maven artifact.

    Args:
        artf: Coordinate of the Maven artifact to generate a pom.xml descriptor for.
        compile_deps: Collection of compile-scoped Artifacts to include in the dependencies.
        test_deps: Collection of test-scoped Artifacts to include in the dependencies.
        exclusions: Optional set of ArtifactName (group ID, artifact ID) to exclude globally.
        pom_template: String template of the pom file. Expects to be able to replace the following
            fields: group_id, artifact_id, version, packaging, dependencies.
        unresolved_deps: Optional list of unresolved dependencies.
        fiji_build_exclusions: fiji-build exclusion list to encode as pom.xml comments.
        java_target_version: Version of the JVM to generate bytecode for.
        java_source_version: Version of the Java source code to compile.
    Returns:
        Content of the pom.xml descriptor for the specified Maven artifact.
    """
    def format_exclusion(aname):
        return MAVEN_EXCLUSION.format(group_id=aname.group_id, artifact_id=aname.artifact_id)

    if len(exclusions) > 0:
        exclusions = map(format_exclusion, sorted(exclusions))
        exclusions = MAVEN_EXCLUSIONS.format(exclusions=" ".join(exclusions))
    else:
        exclusions = ""

    def format_dep(artf, scope):
        classifier = ""
        if (artf.classifier is not None) and (len(artf.classifier) > 0):
            classifier = "<classifier>{}</classifier>".format(artf.classifier)
            classifier = "{:30s}".format(classifier)

        return "    " + MAVEN_DEP.format(
            group_id=element("groupId", artf.group_id),
            artifact_id=element("artifactId", artf.artifact_id),
            version=element("version", artf.version),
            type=element("type", artf.packaging),
            classifier=classifier,
            exclusions=exclusions,
            scope=scope,
        )

    formatted_compile_deps = (format_dep(dep, "compile") for dep in compile_deps)
    formatted_test_deps = (format_dep(dep, "test") for dep in test_deps)

    def format_unresolved_dep(dep):
        return "  <!-- dep: {!s} -->".format(dep)

    unresolved_deps = map(format_unresolved_dep, unresolved_deps)

    def format_fiji_build_exclusions(exclusion):
        return "  <!-- exclusion: {!s} -->".format(exclusion)

    fiji_build_exclusions = sorted(frozenset(fiji_build_exclusions))
    fiji_build_exclusions = map(format_fiji_build_exclusions, fiji_build_exclusions)

    def format_property(name, value):
        """Formats a Maven property."""
        return "    <{name}>{value}</{name}>".format(name=name, value=value)

    maven_artifact_path_in_repo = \
      "${{maven.repo.local}}/{group_id_path}/{artifact_id}/{version}".format(
        group_id_path=artf.group_id.replace(".", "/"),
        artifact_id=artf.artifact_id,
        version=artf.version
      )

    properties = [
        ("maven.compiler.source", java_source_version),
        ("maven.compiler.target", java_target_version),
        ("maven.compiler.testSource", java_source_version),
        ("maven.compiler.testTarget", java_target_version),
        ("maven.artifact.path.in.repo", maven_artifact_path_in_repo)
    ]

    properties = map(lambda prop: format_property(name=prop[0], value=prop[1]), properties)

    return pom_template.format(
        group_id=artf.group_id,
        artifact_id=artf.artifact_id,
        version=artf.version,
        packaging=artf.packaging,
        dependencies="\n".join(itertools.chain(formatted_compile_deps, formatted_test_deps)),
        unresolved_deps="\n".join(unresolved_deps),
        fiji_build_exclusions="\n".join(fiji_build_exclusions),
        properties="\n".join(properties),
    )


# --------------------------------------------------------------------------------------------------
# Python tasks
# --------------------------------------------------------------------------------------------------


class PythonWorkspaceTask(WorkspaceTask):
    """Base class for tasks to operate on Python elements (libraries, binaries, tests, etc).

    Python tasks support incremental builds.
    Python task specifications include sources.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def source_map(self):
        """Returns: the Python sources, as a map: python path -> workspace path."""
        return self.get_source_map(self.spec.sources)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: a fingerprint of the inputs for the Python element produced by this task.

        Sub-classes should overload build_input_fingerprint() to customize the fingerprinted
        content.
        """
        return self.build_input_fingerprint().get()

    def build_input_fingerprint(self):
        """Builds a fingerprint of the inputs for the Python element produced by this task.

        The builder returned by the base class already includes:
         - the task specification record
         - the dependency names and their input fingerprints
         - TODO: a fingerprint of the environment and tooling (Java/Python version, fiji-build...)

        Returns:
            Fingerprint builder preloaded.
        """
        fp = self.tools.new_fingerprint()

        # Include the specification record:
        fp.add_text(str(self.spec))

        # Include the dependency names and their input fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        # Include the Python sources (name and content):
        for python_path, wpath in sorted(self.source_map.items()):
            fp.add_text(python_path)
            fp.add_text(wpath)
            fp.add_file(self.workspace.apath(wpath))
        return fp

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of this task.

        The default behavior is for the output to match the input.
        """
        return self.input_fingerprint

    def get_content_bytes(self, wpath):
        with open(self.workspace.apath(wpath), mode="rb") as f:
            return f.read()

    def merge_content_maps(self, content_maps):
        # Map: relative path -> content bytes
        merged_content_map = dict()

        for content_map in content_maps:
            for path, content_bytes in content_map.items():
                existing_bytes = merged_content_map.get(path)
                if existing_bytes is None:
                    merged_content_map[path] = content_bytes
                elif existing_bytes == content_bytes:
                    log.debug("Duplicate but non-conflicting content for path {!r}", path)
                else:
                    log.error("Conflicting content for path {!r}", path)

        return merged_content_map

    def get_content_map(self):
        """Lists the Python content of this Python element.

        This recursively includes the content of this element's dependencies.

        Returns:
            A map: Python archive path -> workspace file path.
        """
        # Convert build target source map into content map:
        content_map = dict()
        for source_path, wpath in self.source_map.items():
            content_bytes = self.get_content_bytes(wpath)
            content_map[source_path] = content_bytes

            # Enforce namespace package declaration in __init__.py:
            if (os.path.basename(source_path) == "__init__.py") \
               and (content_bytes.strip() != build_tools.INIT_PY.strip()):
                log.warning("{!r} : Python module does not declare namespace package: {!r}",
                            self.name, source_path)

        # Merge target node source map with dependencies source maps:
        content_maps = [content_map]
        for dep_name in self.input:
            dep_output = self.input[dep_name]
            python_content = dep_output.get("python_content", dict())
            content_maps.append(python_content)
        return self.merge_content_maps(content_maps)

    @base.memoized_property
    def pypi_deps(self):
        deps = filter(lambda dep: isinstance(dep, build_defs.PythonPyPIDep), self.spec.deps)
        return frozenset(deps)

    @property
    def task_label(self):
        """Returns: a label to include in the Graphviz representation of this task."""
        raise Error("Abstract property")

    @property
    def graphviz_label(self):
        return "\\n".join([self.task_label, self.name])

    def get_pypi_source_map(self, venv_dir, pypi_deps):
        """Lists the source file mapping corresponding to the declared PyPI dependencies.

        This constructs the source file mapping by creating a Python virtual environment
        and installing the declared PyPI dependencies via pip.
        The source file mapping is then derived from the virtual environment structure,
        by scanning the Python sys.path directory content.

        Args:
            venv_dir: Path to directory where to create a Python virtual environment.
                The directory is not deleted on exit, in order for the source files to exist
                on the file system after the call.
            pypi_deps: Collection of PyPI dependencies to generate a source map for.
        Yields:
            Pairs (Python file path, absolute file path).
            Python file path is relative to the root of the Python executable archive.
        """
        if len(pypi_deps) == 0:
            # Avoid creating a virtual environment in case there is no PyPI dependency:
            return

        python_venv = PythonVirtualEnv(path=venv_dir)

        # Note the pre-existing Python content:
        content_map = dict(python_venv.list_content())

        python_venv.install(self.pypi_deps)

        # Lists the newly installed Python content:
        for pypath, apath in python_venv.list_content():
            if pypath in content_map:
                # Ignore Python content that pre-existed before the install:
                log.debug("Ignoring pre-existing Python content: {} -> {}", pypath, apath)
                pass
            else:
                yield (pypath, apath)


# --------------------------------------------------------------------------------------------------


class PythonVirtualEnv(object):
    """Python virtual environment builder."""

    def __init__(self, path):
        self._path = os.path.abspath(path)

        log.debug("Creating Python virtual environment: {!r}", self.path)
        venv.create(env_dir=self.path, clear=True, symlinks=True, with_pip=True)

        assert os.path.exists(self.python_path), \
            "Cannot find 'pip' executable at: {}".format(self.python_path)
        assert os.path.exists(self.pip_path), \
            "Cannot find 'pip' executable at: {}".format(self.pip_path)

    @property
    def path(self):
        """Returns: the root path of the Python virtual environment."""
        return self._path

    @property
    def pip_path(self):
        return os.path.join(self.path, "bin", "pip")

    @property
    def python_path(self):
        return os.path.join(self.path, "bin", "python")

    def install(self, pypi_deps):
        """Installs a PyPI package in this virtual environment.

        Args:
            pypi_deps: Iterable of PyPI dependencies to install.
        """
        # Installing the PyPI dependencies in the virtual environment:
        args = [self.pip_path, "install"]
        for dep in pypi_deps:
            args.append("{!s}=={!s}".format(dep.name, dep.version))
        cmd = command.Command(args=args, exit_code=0)

    def list_sys_path_entries(self):
        """Reports the Python system path for this virtual environment.

        Yields:
            Absolute system path entries.
        """
        # Extract python path entries from the virtual environment:
        script = base.strip_margin("""\
        |import sys
        |print("\\n".join(sys.path))
        """)
        cmd = command.Command(args=[self.python_path, "-c", script], exit_code=0)

        for line in cmd.output_lines:
            path = os.path.abspath(line)
            # Ignore Python path entries outside of the virtual environment:
            if path.startswith(self.path):
                yield path

    def list_content(self):
        """Reports the python content in this virtual environment.

        Yields:
           Entries: (Python archive relative path, absolute file path).
        """
        for path in self.list_sys_path_entries():
            for root_dir, dirnames, filenames in os.walk(path):
                try:
                    dirnames.remove("__pycache__")
                except ValueError:
                    pass  # no __pycache__ sub-directory to exclude here
                dirnames.sort()
                for filename in sorted(filenames):
                    if filename.endswith(".pyc"):
                        # Exclude *.pyc
                        continue
                    file_path = os.path.join(root_dir, filename)
                    yield (os.path.relpath(file_path, path), file_path)


# --------------------------------------------------------------------------------------------------


class PythonLibraryTask(PythonWorkspaceTask):
    """Task to construct a Python library.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        python_content: Dictionary of the Python (Python archive path, workspace file path).
    """

    @property
    def task_label(self):
        return "Build Python Library"

    def run_with_io(self, output, **inputs):
        # Map: source path -> content bytes
        content_map = self.get_content_map()

        with tempfile.TemporaryDirectory(dir=self.workspace.temp_dir) as venv_dir:
            pypi_source_map = self.get_pypi_source_map(venv_dir, pypi_deps=self.pypi_deps)
            pypi_content_map = dict()
            for source_path, apath in pypi_source_map:
                with open(apath, mode="rb") as f:
                    content_bytes = f.read()
                pypi_content_map[source_path] = content_bytes

        content_map = self.merge_content_maps([content_map, pypi_content_map])

        # Nothing to compile here.

        # Ideally, we could validate Python's syntax by running a parser.
        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint

        # Map: Python archive path -> content bytes
        output.python_content = content_map

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class PythonBinaryTask(PythonWorkspaceTask):
    """Task to construct a Python binary.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        python_content: Dictionary of the Python (Python archive path, workspace file path).
    """

    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec,
        force=False,
    ):
        super().__init__(
            workflow=workflow,
            workspace=workspace,
            name=name,
            spec=spec,
            force=force,
        )
        self._binary_apath = self.tools.resolve_binary_name(self.name)

    @property
    def task_label(self):
        return "Build Python Executable"

    @property
    def binary_apath(self):
        return self._binary_apath

    @property
    def output_fingerprint(self):
        """Overrides the base fingerprint: output is the executable binary."""
        fp = self.tools.new_fingerprint()
        fp.add_text(self.tools.wkspc_relpath(self.binary_apath))
        fp.add_file(self.binary_apath, missing_ok=True)
        return fp.get()

    def run_with_io(self, output, **inputs):
        # Map: source path -> content bytes
        content_map = self.get_content_map()

        with tempfile.TemporaryDirectory(dir=self.workspace.temp_dir) as venv_dir:
            pypi_source_map = self.get_pypi_source_map(venv_dir, pypi_deps=self.pypi_deps)
            pypi_content_map = dict()
            for source_path, apath in pypi_source_map:
                with open(apath, mode="rb") as f:
                    content_bytes = f.read()
                pypi_content_map[source_path] = content_bytes

        content_map = self.merge_content_maps([content_map, pypi_content_map])

        # Link executable:
        self.tools.link_python_binary(
            path=self.binary_apath,
            content_map=content_map,
            main_module=self.spec.main_module,
        )

        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.python_content = content_map
        output.output_files = [self.binary_apath]

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class PythonTestTask(PythonBinaryTask):
    """Task to construct a Python test binary.

    Tests must be placed in Python modules whose name start with the prefix 'test_'.

    This is a subclass of a PythonBinaryTask because it does the same thing as the
    BinaryTask with the additional step of including a list of test modules in output.test_modules.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        python_content: Dictionary of the Python (Python archive path, workspace file path).
        output_files: Collection of the files generated by this task (executable).
        test_modules: Collection of the Python modules with unit-tests to run.
    """

    @property
    def task_label(self):
        return "Build Python Test"

    def run_with_io(self, output, **inputs):
        state = super().run_with_io(output, **inputs)
        if state == workflow.TaskState.SUCCESS:
            def python_path_to_module(pypath):
                """Converts a Python file path into a Python module name.

                Returns:
                    Python module name. None if the file path does not correspond to a Python module.
                """
                if not pypath.endswith(".py"):
                    return None
                pypath = pypath[:-3]
                return pypath.replace("/", ".")

            output.test_modules = []
            content_map = self.get_content_map()
            for pypath in content_map.keys():
                module = python_path_to_module(pypath)
                if (module is not None) and module.split(".")[-1].startswith("test_"):
                    output.test_modules.append(module)
        return state


# --------------------------------------------------------------------------------------------------


class RunPythonTestTask(WorkspaceTask):
    """Task to run Python tests produced by a PythonTestTask.

    This task has no output.
    Eventually, the output might include the details of the test run (eg. timings, failures, etc).
    """
    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec=None,
        force=False,
    ):
        super().__init__(
            workflow=workflow,
            workspace=workspace,
            name=name,
            spec=spec,
            force=force or not workspace.config.enable_incremental_tests,
        )

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: a fingerprint of the Python elements tested by this task."""
        fp = self.tools.new_fingerprint()

        # Include the specification record:
        fp.add_text(str(self.spec))

        # Include the dependency names and their input fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    def run_with_io(self, output, **inputs):
        assert (len(inputs) == 1), \
            "Internal error: expecting exactly one input dependency: {!r}".format(inputs)
        (build_task_name, build_task) = next(iter(inputs.items()))

        success = True
        output.run_map = dict()

        for test_binary in build_task.output_files:
            test_binary = self.tools.resolve_wpath(test_binary)
            cmd_args = [test_binary]
            cmd_args.extend(build_task.test_modules)
            cmd = command.Command(
                args=cmd_args,
                # Don't pass test output to python as there may be a lot of it.
                direct_log=True,
                collect_log=not self.workspace.config.separate_test_logs,
                wait_for=False,
            )
            if self.workspace.config.separate_test_logs:
                log.info(
                    "Log files for {!r}:\n"
                    "\tstderr: {}\n"
                    "\tstdout: {}",
                    self.name,
                    self.printable_test_log_path(
                        log_path=cmd.error_path,
                        log_path_prefix=self.workspace.config.test_log_prefix
                    ),
                    self.printable_test_log_path(
                        log_path=cmd.output_path,
                        log_path_prefix=self.workspace.config.test_log_prefix
                    ),
                )
            else:
                log.info("Python test output for {!r}:{}", self.name, format_command_output(cmd))
            cmd.wait_for()

            output.run_map[test_binary] = record.Record(params=dict(
                test_binary=test_binary,
                command_line=cmd_args,
                exit_code=cmd.exit_code,
                output=cmd.output_text,
                error=cmd.error_text,
            ))

            if cmd.exit_code != 0:
                success = False

        if success:
            return workflow.TaskState.SUCCESS
        else:
            return workflow.TaskState.FAILURE

    @property
    def graphviz_label(self):
        return "\\n".join(["Run Python Test", self.name])


# --------------------------------------------------------------------------------------------------
# Java tasks
# --------------------------------------------------------------------------------------------------


class AvroJavaLibraryTask(WorkspaceTaskForArtifact):
    """Task to build a Java library for an Avro IDL definition.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: List of the generated output files (JAR and POM descriptor file paths).
        maven_artifacts: List of the generated Maven artifact coordinates.
        javac_output: Standard output text emitted by the Java compiler.
        javac_error: Standard error text emitted by the Java compiler.
        resolved_deps: Resolved dependencies of this library. Only includes avro for this type of
            task.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def sources(self):
        """Returns: workspace path of the Avro IDL, schema or protocol files to compile."""
        return sorted(self.tools.glob(*self.spec.sources))

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))
        for source_wpath in self.sources:
            fp.add_text(source_wpath)
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)
        return fp.get()

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()

        # Fingerprint the JAR file:
        jar_wpath = self.tools.artifact_wpath(self.artifact)
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(jar_wpath), missing_ok=True)

        # Fingerprint the POM file:
        pom_wpath = self.tools.artifact_wpath(self.artifact.update(packaging="pom"))
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(pom_wpath), missing_ok=True)

        return fp.get()

    _SUMMARY_FORMAT = base.strip_margin(
        """Avro java library summary '{name}':
        |Requires: {requires}
        |Provides: {provides}
        |Global Maven exclusions:
        |{exclusions}
        |Build dependencies:
        |{build_deps}
        |Declared dependencies:
        |{declared_deps}
        """
    )

    def run_with_io(self, output, **inputs):
        gen_wpath = os.path.join("//output/generated", self.name[2:].replace(":", "/"))
        gen_path = self.tools.resolve_wpath(gen_wpath)

        gen_java_path = os.path.join(gen_path, "java")

        if os.path.exists(gen_path):
            shutil.rmtree(gen_path)
        os.makedirs(gen_path, exist_ok=True)

        os.makedirs(gen_java_path, exist_ok=True)

        # Resolve the dependencies for this task.
        avro_java_library_deps = list(self.spec.deps)
        avro_java_library_deps.append(self.tools.avro_lib_artifact)
        if self.spec.ipc:
            avro_java_library_deps.append(self.tools.avro_ipc_artifact)
        (build_deps, declared_deps, exclusions, dynamic_deps, provided_slots) = \
            self.tools.get_java_deps(
                spec_name=self.spec.name,
                deps=avro_java_library_deps,
                maven_exclusions=self.spec.get("maven_exclusions", tuple()),
                provided_slots=tuple(),
                inputs=inputs,
                workflow=self.workflow
            )

        log.debug(
            self._SUMMARY_FORMAT,
            name=self.name,
            requires=sorted(dynamic_deps.keys()),
            provides=sorted(provided_slots),
            build_deps=lazy(lambda: "\n".join(map(indent_line, map(str, build_deps)))),
            declared_deps=lazy(lambda: "\n".join(map(indent_line, map(str, declared_deps)))),
            exclusions=lazy(lambda: "\n".join(map(indent_line, map(str, sorted(exclusions))))),
        )

        with tempfile.TemporaryDirectory(
            dir=self.workspace.temp_dir,
            prefix="java-classes.",
        ) as temp_classes_dir, \
        tempfile.NamedTemporaryFile(
            dir=self.workspace.temp_dir,
            prefix="avro_java_library.",
            suffix=".jar",
        ) as temp_jar:
            # Compile .avdl source files into .avpr protocol definitions:
            avro_defs = []
            for source_wpath in self.sources:
                if source_wpath.endswith(".avdl"):
                    generated_path = os.path.join(gen_path, source_wpath[2:-5] + ".avpr")
                    self.tools.compile_avro_idl(
                        avdl_source_path=self.tools.resolve_wpath(source_wpath),
                        avpr_target_path=generated_path,
                    )
                    avro_defs.append(self.tools.wkspc_relpath(generated_path))
                else:
                    avro_defs.append(source_wpath)

            # Compile .avsc and .avpr sources into Java sources:
            for avro_def in avro_defs:
                logging.debug("Compiling Avro definition %r", avro_def)
                if avro_def.endswith(".avpr"):
                    self.tools.compile_avro_protocol_to_java(
                        avpr_source_path=self.tools.resolve_wpath(avro_def),
                        source_dir=gen_java_path,
                    )
                else:
                    self.tools.compile_avro_schema_to_java(
                        avsc_source_path=self.tools.resolve_wpath(avro_def),
                        source_dir=gen_java_path,
                    )

            # Compile generated Java sources:
            sources = self.tools.list_java_files(gen_java_path)

            build_classpath = self.tools.get_classpath(
                artifacts=build_deps,
                exclusions=exclusions,
                scope="compile",
            )
            javac = self.tools.compile_java(
                sources=sources,
                build_classpath=build_classpath,
                classes_dir=temp_classes_dir,
            )
            if javac.exit_code != 0:
                return workflow.TaskState.FAILURE

            self.tools.build_jar(
                temp_classes_dir,
                jar_file_path=temp_jar.name,
            )

            installed_jar_path = self.tools.maven_repo_install(
                artifact=self.artifact,
                path=temp_jar.name,
            )

            lib_deps = [self.tools.avro_lib_artifact]
            if self.spec.ipc:
                lib_deps.append(self.tools.avro_ipc_artifact)

            maven_deps = self.tools.resolve_deps(
                artifacts=lib_deps,
                scope="compile",
                exclusions=exclusions,
            )
            maven_deps = sorted(maven_deps)
            pom_file_content = format_pom_file(
                artf=self.artifact,
                compile_deps=maven_deps,
                exclusions=frozenset({ANY_ARTIFACT_NAME}),
                unresolved_deps=lib_deps,
                fiji_build_exclusions=exclusions,
            )
            installed_pom_path = self.tools.maven_repo_install(
                artifact=self.artifact.update(packaging="pom"),
                text=pom_file_content,
            )

        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.output_files = [
            self.tools.wkspc_relpath(installed_jar_path),
            self.tools.wkspc_relpath(installed_pom_path),
        ]

        output.maven_artifacts = [self.artifact]
        output.javac_output = javac.output_text.strip()
        output.javac_error = javac.error_text.strip()
        output.resolved_deps = list(map(str, self.tools.resolve_deps(
            artifacts=[self.tools.avro_lib_artifact],
            scope="compile",
            exclusions=exclusions,
        )))

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class JavaLibraryTask(WorkspaceTaskForArtifact):
    """Task to construct a Java library.

    A Java library produces a Maven artifact.

    Specification includes the following fields:
     - name: unique task name
     - sources: collection of source directories (containing .java files to compile)
     - resources: collection of resource directories (included, but not compiled)
     - deps: dependencies on other tasks (by name)
     - maven_deps: collection of Maven dependency specifications (taking precedence)
     - version: optional explicit version ID for the Maven artifact
     - processors: collection of Java pre-processor class names
     - processor_deps: collection of runtime dependencies for the processors

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of the files generated by this task.
           Workspace relative paths of the generated JAR and POM descriptor.
        maven_artifacts: Collection of Maven artifact coordinates produced by this task.
        dynamic_deps: Map from dynamic slot name to the selected concrete provider, eg.
            "fiji_platform" -> //com/moz/fiji/platforms:cdh5.2-platform
        provided_slots: Collection of slot names provided by this Java library, eg. "fiji_platform".
        javac_output: Standard output text emitted by the Java compiler.
        javac_error: Standard error text emitted by the Java compiler.
        resolved_deps: Resolved dependencies of this library.
    """

    def __init__(self, **kwargs):
        # Bypass WorkspaceTaskForArtifact to override the logic to infer the artifact ID:
        WorkspaceTask.__init__(self, **kwargs)

        library_name = self.name
        if self.spec.library_name is not None:
            library_name = self.spec.library_name

        aname = artifact_from_name(library_name)
        version = self.workspace.config.maven_artifact_version
        if self.spec.version is not None:
            version = self.spec.version
        self._artifact = artifact.Artifact(
            group_id=aname.group_id,
            artifact_id=aname.artifact_id,
            version=version,
        )

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def java_sources(self):
        """Returns: workspace path of the Java source files to compile."""
        sources = []
        for src_dir in self.spec.sources:
            sources.extend(self.tools.glob(os.path.join(src_dir, "**.java")))
        return sorted(sources)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        for source_wpath in self.java_sources:
            fp.add_text(source_wpath)
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)

        # Include resources:
        for resource_wdir in self.spec.resources:
            fp.add_dir(self.tools.resolve_wpath(resource_wdir))

        # Include direct dependencies fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()

        # Fingerprint the JAR file:
        jar_wpath = self.tools.artifact_wpath(self.artifact)
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(jar_wpath), missing_ok=True)

        # Fingerprint the POM file:
        pom_wpath = self.tools.artifact_wpath(self.artifact.update(packaging="pom"))
        fp.add_text(pom_wpath)
        fp.add_file(self.tools.resolve_wpath(pom_wpath), missing_ok=True)

        return fp.get()

    _SUMMARY_FORMAT = base.strip_margin(
        """Java library summary '{name}':
        |Requires: {requires}
        |Provides: {provides}
        |Global Maven exclusions:
        |{exclusions}
        |Build dependencies:
        |{build_deps}
        |Declared dependencies:
        |{declared_deps}
        """
    )

    def run_with_io(self, output, **inputs):
        with tempfile.TemporaryDirectory(
                dir=self.workspace.temp_dir,
                suffix=".classes",
        ) as classes_dir, \
            tempfile.NamedTemporaryFile(
                dir=self.workspace.temp_dir,
                suffix=".jar",
        ) as jar_file_path:

            (build_deps, declared_deps, exclusions, dynamic_deps, provided_slots) = \
                self.tools.get_java_deps(
                    spec_name=self.spec.name,
                    deps=self.spec.deps,
                    maven_exclusions=self.spec.get("maven_exclusions", tuple()),
                    provided_slots=self.spec.get("provides", tuple()),
                    inputs=inputs,
                    workflow=self.workflow
                )

            log.debug(
                self._SUMMARY_FORMAT,
                name=self.name,
                requires=sorted(dynamic_deps.keys()),
                provides=sorted(provided_slots),
                build_deps=lazy(lambda: "\n".join(map(indent_line, map(str, build_deps)))),
                declared_deps=lazy(lambda: "\n".join(map(indent_line, map(str, declared_deps)))),
                exclusions=lazy(lambda: "\n".join(map(indent_line, map(str, sorted(exclusions))))),
            )

            # Assemble the build classpath:
            resolved_build_deps = self.tools.resolve_deps(
                artifacts=build_deps,
                exclusions=exclusions,
                scope="compile",
            )
            resolved_build_deps = sorted(resolved_build_deps)
            logging.debug("Resolved build dependencies for Java library %r:\n%s",
                          self.name, "\n".join(map(lambda x: "\t" + str(x), resolved_build_deps)))

            build_classpath = map(self.tools.resolve_maven_artifact, resolved_build_deps)
            build_classpath = sorted(build_classpath)

            logging.debug(
                "Compiling Java sources %r "
                "into classes in directory %r "
                "using build classpath %r",
                self.java_sources, classes_dir, build_classpath)

            processor_maven_deps = []
            for dep in self.spec.processor_deps:
                processor_maven_deps.extend(inputs[dep].maven_artifacts)
            processor_classpath = self.tools.get_classpath(
                artifacts=processor_maven_deps,
                scope="runtime",
            )

            if len(self.java_sources) > 0:
                javac = self.tools.compile_java(
                    sources=self.java_sources,
                    build_classpath=build_classpath,
                    classes_dir=classes_dir,
                    processor_classpath=processor_classpath,
                    processors=self.spec.processors,
                )
                output.javac_output = javac.output_text.strip()
                output.javac_error = javac.error_text.strip()
                if javac.exit_code == 0:
                    logging.info("Java compilation for %r successful: %s",
                                 self.name, format_command_output(javac))
                else:
                    logging.error("Java compilation for %r failed: %s",
                                  self.name, format_command_output(javac))
                    return workflow.TaskState.FAILURE
            else:
                javac = None
                logging.debug("No Java source files to compile for %r", self.name)

            dirs = [classes_dir]
            for resource_wdir in self.spec.resources:
                dirs.append(self.tools.resolve_wpath(resource_wdir))

            self.tools.build_jar(jar_file_path=jar_file_path.name, *dirs)

            maven_deps = self.tools.resolve_deps(
                artifacts=declared_deps,
                exclusions=exclusions,
                scope="compile",
            )
            maven_deps = tuple(maven_deps)  # Do no sort, maintain resolved ordering
            self.validate_classpath(maven_deps)

            pom_file_content = format_pom_file(
                artf=self.artifact,
                compile_deps=maven_deps,
                exclusions=frozenset({ANY_ARTIFACT_NAME}),
                unresolved_deps=declared_deps,
                fiji_build_exclusions=exclusions,
            )

            pom_file_path = self.tools.maven_repo_install(
                artifact=self.artifact.update(packaging="pom"),
                text=pom_file_content,
            )
            jar_file_path = self.tools.maven_repo_install(
                artifact=self.artifact,
                path=jar_file_path.name,
            )

            output.input_fingerprint = self.input_fingerprint
            output.output_fingerprint = self.output_fingerprint
            output.output_files = [
                self.tools.wkspc_relpath(pom_file_path),
                self.tools.wkspc_relpath(jar_file_path),
            ]

            output.maven_artifacts = [self.artifact]
            output.resolved_deps = list(map(str, resolved_build_deps))
            output.dynamic_deps = dynamic_deps
            output.provided_slots = provided_slots

            return workflow.TaskState.SUCCESS

    def validate_classpath(self, deps):
        """Validates the classpath generated after the specified ordered artifact list.

        Args:
            deps: Ordered collection of resolved dependencies.
        """
        cp_entries = list()
        for dep in deps:
            cp_entries.append(self.workspace.maven_repo.get(dep))
        java_linker.log_jar_conflicts(
            cp_entries,
            maven_repo=self.workspace.maven_repo,
            name=self.name,
        )

    @property
    def graphviz_label(self):
        return "\\n".join(["Build Java Library", self.name])


# --------------------------------------------------------------------------------------------------


class JavaBinaryTask(WorkspaceTask):
    """Task to link a Java executable.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of files generated by this task,
            ie. the workspace relative path of the Java executable.
    """

    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec,
        force=False,
    ):
        super().__init__(
            workflow=workflow,
            workspace=workspace,
            name=name,
            spec=spec,
            force=force,
        )
        binary_name = self.spec.binary_name
        if binary_name is None:
            binary_name = self.name
        self._binary_apath = self.tools.resolve_binary_name(binary_name)

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @property
    def binary_apath(self):
        return self._binary_apath

    @property
    def input_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include dependencies:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(self.tools.wkspc_relpath(self.binary_apath))
        fp.add_file(self.binary_apath, missing_ok=True)
        return fp.get()

    def run_with_io(self, output, **inputs):
        logging.info("Linking Java binary %r", self.name)

        # Assemble the runtime classpath:
        (build_deps, declared_deps, exclusions, dynamic_deps, provided_slots) = \
            self.tools.get_java_deps(
                spec_name=self.spec.name,
                deps=self.spec.deps,
                maven_exclusions=self.spec.get("maven_exclusions", tuple()),
                provided_slots=self.spec.get("provides", tuple()),
                inputs=inputs,
                workflow=self.workflow
            )

        logging.debug(
            "Summary for Java binary %r:\n"
            " - requires: %r\n"
            " - provides: %r\n"
            " - build_deps: %r\n"
            " - declared_deps: %r\n"
            " - global maven exclusions: %r\n",
            self.name,
            sorted(dynamic_deps.items()),
            sorted(provided_slots),
            build_deps,
            declared_deps,
            sorted(exclusions),
        )

        for slot, dep in dynamic_deps.items():
            if (dep is base.UNDEFINED) and (slot not in provided_slots):
                logging.error("Slot %r is not fulfilled", slot)

        resolved_deps = self.tools.resolve_deps(
            artifacts=build_deps,
            exclusions=exclusions,
            scope="runtime",
        )
        resolved_deps = list(resolved_deps)
        logging.debug("Resolved dependencies for Java binary %r:\n%s",
                      self.name, "\n".join(sorted(map(str, resolved_deps))))

        os.makedirs(os.path.dirname(self.binary_apath), exist_ok=True)
        base.remove(self.binary_apath)

        # Write the resolved dependencies file:
        with open("{}.deps".format(self.binary_apath), mode="wt", encoding="utf-8") as f:
            for dep in sorted(resolved_deps):
                f.write("{}\n".format(dep))

        linker = java_linker.JavaLinker(
            output_path=self.binary_apath,
            maven_repo=self.tools.workspace.maven_repo,
        )
        output.config = linker.link(
            artifacts=resolved_deps,
            main_class=self.spec.main_class,
            jvm_args=self.spec.jvm_args,
        )
        linker.close()

        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.output_files = [
            self.tools.wkspc_relpath(self.binary_apath),
        ]
        output.build_deps = list(map(str, build_deps))
        output.resolved_deps = list(map(str, resolved_deps))

        return workflow.TaskState.SUCCESS

    @property
    def graphviz_label(self):
        return "\\n".join(["Build Java Binary", self.name])


# --------------------------------------------------------------------------------------------------


class JavaSuperBinaryTask(WorkspaceTask):
    """Task to package a collection of Java executables into a super binary.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of files generated by this task,
            ie. the workspace relative path of the Java executable.
    """

    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec,
        force=False,
    ):
        super().__init__(
            workflow=workflow,
            workspace=workspace,
            name=name,
            spec=spec,
            force=force,
        )
        binary_name = self.spec.binary_name
        if binary_name is None:
            binary_name = self.name
        self._binary_apath = self.tools.resolve_binary_name(binary_name)

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @property
    def binary_apath(self):
        return self._binary_apath

    @property
    def input_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include dependencies:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(self.tools.wkspc_relpath(self.binary_apath))
        fp.add_file(self.binary_apath, missing_ok=True)
        return fp.get()

    def run_with_io(self, output, **inputs):
        log.info("Linking Java super binary {!r}", self.name)

        os.makedirs(os.path.dirname(self.binary_apath), exist_ok=True)
        base.remove(self.binary_apath)

        # Map: profile name -> Profile record
        profile_map = dict()
        for name, input in inputs.items():
            if "config" not in input:
                # Not a java_binary() dependency, skip...
                continue

            for profile_name, profile in input.config["profiles"].items():
                assert (profile_name not in profile_map), \
                    "Duplicate profile name {!r}".format(profile_name)
                profile_map[profile_name] = profile

        maven_repo = self.tools.workspace.maven_repo
        linker = java_linker.JavaLinker(
            output_path=self.binary_apath,
            maven_repo=maven_repo,
        )

        # Take the union of all the Maven artifacts to package together:
        artifacts = set()
        for profile in profile_map.values():
            artifacts.update(profile["artifacts"])
        artifacts = frozenset(map(artifact.parse_artifact, artifacts))

        # Map: archive relative path -> absolute file path
        entry_map = dict()
        for artf in artifacts:
            entry_map[linker.archive_relpath_for_artifact(artf)] = maven_repo.get(artf)

        assert (self.spec.default_profile in profile_map), \
            "Unknown default profile {!r}, available profiles are {}" \
            .format(self.spec.default_profile, sorted(profile_map.keys()))
        config = dict(
            artifacts=tuple(sorted(map(str, artifacts))),
            profiles=profile_map,
            default_profile=self.spec.default_profile,
        )

        linker.write_header(java_linker.PYTHON_EXE_HEADER)
        linker.write_python_launcher(config=config)
        linker.write_entries(entry_map)

        linker.close()

        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.output_files = [
            self.tools.wkspc_relpath(self.binary_apath),
        ]
        output.config = config

        return workflow.TaskState.SUCCESS

    @property
    def graphviz_label(self):
        return "\\n".join(["Build Java Super Binary", self.name])


# --------------------------------------------------------------------------------------------------


JUNIT4_RUNNER_CLASS = "org.junit.runner.JUnitCore"


class JavaTestTask(WorkspaceTask):
    """Task to build a Java test.

    This task does not run the test.
    Java unit-tests are identified by the @Test JUnit annotation.
    Concrete unit-tests to run must belong to a class whose name starts with the prefix "Test".

    A Java test task named //path:test is internally decomposed into 2 nodes:
     - a java_library() //path:test-lib containing the test classes;
     - and a java_binary() //path:test-bin that bundles the test classes with the JUnit runner.

    JavaTestTask identifies the JUnit test classes to run by parsing the Java compiler output
    emitted by the java_library() internal node.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of the files produced by this task,
            ie. the Java unit-test executable to run.
        test_classes: Collection of the test classes to run through the JUnit runner.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include dependencies:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_fingerprint(self):
        return self.input["java_binary({})".format(self.name)].output_fingerprint

    def run_with_io(self, output, **inputs):
        java_test_lib = inputs["java_library({})".format(self.name)]
        java_test_bin = inputs["java_binary({})".format(self.name)]
        output.output_files = java_test_bin.output_files

        lines = java_test_lib.get("javac_output", "").split("\n")
        lines = map(str.strip, lines)
        prefix = "TestAnnotationCollector: "
        lines = filter(lambda l: l.startswith(prefix), lines)
        lines = map(lambda l: l[len(prefix):-2], lines)  # Parse annotation collector output
        lines = map(lambda l: ".".join(l.split(".")[:-1]), lines)  # Extract class names
        lines = filter(lambda l: l.split(".")[-1].startswith("Test"), lines)
        test_classes = sorted(frozenset(lines))
        logging.debug("Java tests for %r include classes: %s", self.name, " ".join(test_classes))

        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.test_classes = test_classes

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class RunJavaTestTask(WorkspaceTask):
    """Task to run Java tests.

    This task post-processes the output of the JavaTestTask.
    Currently, this task has no output, although we might want to eventually include test results.
    """

    def __init__(
        self,
        workflow,
        workspace,
        name,
        spec,
        force=False,
    ):
        super().__init__(
            workflow=workflow,
            workspace=workspace,
            name=name,
            spec=spec,
            force=force or not workspace.config.enable_incremental_tests,
        )

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: a fingerprint of the Java elements tested by this task."""
        fp = self.tools.new_fingerprint()

        # Include the specification record:
        fp.add_text(str(self.spec))

        # Include the dependency names and their input fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    def run_with_io(self, output, **inputs):
        assert (len(inputs) == 1), \
            "Internal error: expecting exactly one input dependency: {!r}".format(inputs)
        (build_task_name, build_task) = next(iter(inputs.items()))

        for test_binary in build_task.output_files:
            test_binary = self.tools.resolve_wpath(test_binary)
            cmd_args = [test_binary]
            # Get JVM args to pass to test runner.
            cmd_args.extend(build_task.test_classes)
            run_test = command.Command(
                args=cmd_args,
                # Don't pass test output to python as there may be a lot of it.
                direct_log=True,
                collect_log=not self.workspace.config.separate_test_logs,
                wait_for=False,
            )
            if self.workspace.config.separate_test_logs:
                log.info(
                    "Log files for {!r}:\n"
                    "\tstderr: {}\n"
                    "\tstdout: {}",
                    self.name,
                    self.printable_test_log_path(
                        log_path=run_test.error_path,
                        log_path_prefix=self.workspace.config.test_log_prefix
                    ),
                    self.printable_test_log_path(
                        log_path=run_test.output_path,
                        log_path_prefix=self.workspace.config.test_log_prefix
                    ),
                )
            else:
                log.info("Java test output for {!r}: {}",
                         self.name, format_command_output(run_test))
            run_test.wait_for()
            if run_test.exit_code != 0:
                return workflow.TaskState.FAILURE
        return workflow.TaskState.SUCCESS

    @property
    def graphviz_label(self):
        return "\\n".join(["Run Java Test", self.name])


# --------------------------------------------------------------------------------------------------


class ScalaLibraryTask(WorkspaceTaskForArtifact):
    """Task to construct a Scala library.

    Scala libraries may also include Java code.
    Java code is compiled before the Scala code, ie. the Java code may not reference Scala elements.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of the files generated by this task.
           Workspace relative paths of the generated JAR and POM descriptor.
        maven_artifacts: Collection of Maven artifact coordinates produced by this task.
        dynamic_deps: Map from dynamic slot name to the selected concrete provider, eg.
            "fiji_platform" -> //com/moz/fiji/platforms:cdh5.2-platform
        provided_slots: Collection of slot names provided by this Java library, eg. "fiji_platform".
        javac_output: Standard output text emitted by the Java compiler.
        javac_error: Standard error text emitted by the Java compiler.
        scalac_output: Standard output text emitted by the Scala compiler.
        scalac_error: Standard error text emitted by the Scala compiler.
        resolved_deps: Resolved dependencies of this library.
    """

    @base.memoized_property
    def all_sources(self):
        """Returns: workspace path of the Java and Scala source files to compile."""
        sources = []
        for src_dir in self.spec.sources:
            sources.extend(self.tools.glob(os.path.join(src_dir, "**.java")))
            sources.extend(self.tools.glob(os.path.join(src_dir, "**.scala")))
        return sorted(sources)

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        for source_wpath in self.all_sources:
            fp.add_text(source_wpath)
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)

        # Include resources:
        for resource_wdir in self.spec.resources:
            fp.add_dir(self.tools.resolve_wpath(resource_wdir))

        # Include direct dependencies fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()

        # Fingerprint the JAR file:
        jar_wpath = self.tools.artifact_wpath(self.artifact)
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(jar_wpath), missing_ok=True)

        # Fingerprint the POM file:
        pom_wpath = self.tools.artifact_wpath(self.artifact.update(packaging="pom"))
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(pom_wpath), missing_ok=True)

        return fp.get()

    _SUMMARY_FORMAT = base.strip_margin(
        """Scala library summary '{name}':
        |Requires: {requires}
        |Provides: {provides}
        |Global Maven exclusions:
        |{exclusions}
        |Build dependencies:
        |{build_deps}
        |Declared dependencies:
        |{declared_deps}
        """
    )

    def run_with_io(self, output, **inputs):
        with tempfile.TemporaryDirectory(
                dir=self.workspace.temp_dir,
                suffix=".classes",
        ) as classes_dir, \
            tempfile.NamedTemporaryFile(
                dir=self.workspace.temp_dir,
                suffix=".jar",
        ) as jar_file_path:
            logging.debug("Generating classes in %r", classes_dir)

            (build_deps, declared_deps, exclusions, dynamic_deps, provided_slots) = \
                self.tools.get_java_deps(
                    spec_name=self.spec.name,
                    deps=self.spec.deps,
                    maven_exclusions=self.spec.get("maven_exclusions", tuple()),
                    provided_slots=self.spec.get("provides", tuple()),
                    inputs=inputs,
                    workflow=self.workflow
                )

            build_deps.append(self.tools.scala_lib_artifact)
            declared_deps.append(self.tools.scala_lib_artifact)

            log.debug(
                self._SUMMARY_FORMAT,
                name=self.name,
                requires=sorted(dynamic_deps.keys()),
                provides=sorted(provided_slots),
                build_deps=lazy(lambda: "\n".join(map(indent_line, map(str, build_deps)))),
                declared_deps=lazy(lambda: "\n".join(map(indent_line, map(str, declared_deps)))),
                exclusions=lazy(lambda: "\n".join(map(indent_line, map(str, sorted(exclusions))))),
            )

            # Assemble the build classpath:
            resolved_build_deps = self.tools.resolve_deps(
                artifacts=build_deps,
                exclusions=exclusions,
                scope="compile",
            )
            resolved_build_deps = sorted(resolved_build_deps)
            logging.debug("Resolved build dependencies for Scala library %r:\n%s",
                          self.name, "\n".join(map(lambda x: "\t" + str(x), resolved_build_deps)))

            build_classpath = map(self.tools.resolve_maven_artifact, resolved_build_deps)
            build_classpath = sorted(build_classpath)

            # Compile Java sources:
            java_sources = sorted(filter(lambda f: f.endswith(".java"), self.all_sources))
            if len(java_sources) > 0:
                javac = self.tools.compile_java(
                    sources=java_sources,
                    build_classpath=build_classpath,
                    classes_dir=classes_dir,
                )
                output.javac_output = javac.output_text.strip()
                output.javac_error = javac.error_text.strip()
                if javac.exit_code == 0:
                    logging.info("Java compilation for %r succeeded: %s",
                                 self.name, format_command_output(javac))
                else:
                    logging.error("Java compilation for %r failed: %s",
                                  self.name, format_command_output(javac))
                    return workflow.TaskState.FAILURE
            else:
                javac = None
                logging.debug("No Java source files to compile for %r", self.name)

            # Compile Scala sources:
            if len(self.all_sources) > 0:
                scalac = self.tools.compile_scala(
                    sources=self.all_sources,
                    build_classpath=build_classpath,
                    classes_dir=classes_dir,
                )
                output.scalac_output = scalac.output_text.strip()
                output.scalac_error = scalac.error_text.strip()
                if scalac.exit_code == 0:
                    logging.info("Scala compilation for %r succeeded: %s",
                                 self.name, format_command_output(scalac))
                else:
                    logging.error("Scala compilation for %r failed: %s",
                                  self.name, format_command_output(scalac))
                    return workflow.TaskState.FAILURE
            else:
                scalac = None
                logging.debug("No Scala source files to compile for %r", self.name)

            dirs = [classes_dir]
            for resource_wdir in self.spec.resources:
                dirs.append(self.tools.resolve_wpath(resource_wdir))

            self.tools.build_jar(jar_file_path=jar_file_path.name, *dirs)

            maven_deps = self.tools.resolve_deps(
                artifacts=declared_deps,
                exclusions=exclusions,
                scope="compile",
            )
            maven_deps = sorted(maven_deps)
            pom_file_content = format_pom_file(
                artf=self.artifact,
                compile_deps=maven_deps,
                exclusions=frozenset({ANY_ARTIFACT_NAME}),
                unresolved_deps=declared_deps,
                fiji_build_exclusions=exclusions,
            )

            pom_file_path = self.tools.maven_repo_install(
                artifact=self._artifact.update(packaging="pom"),
                text=pom_file_content,
            )
            jar_file_path = self.tools.maven_repo_install(
                artifact=self._artifact,
                path=jar_file_path.name,
            )

            output.input_fingerprint = self.input_fingerprint
            output.output_fingerprint = self.output_fingerprint
            output.output_files = [
                self.tools.wkspc_relpath(pom_file_path),
                self.tools.wkspc_relpath(jar_file_path),
            ]
            output.maven_artifacts = [self.artifact]
            output.resolved_deps = list(map(str, resolved_build_deps))
            output.dynamic_deps = dynamic_deps
            output.provided_slots = provided_slots

            return workflow.TaskState.SUCCESS

    @property
    def graphviz_label(self):
        return "\\n".join(["Build Scala Library", self.name])


# --------------------------------------------------------------------------------------------------


class ScalaTestTask(WorkspaceTask):
    """Task to build a Scala test.

    This task does not run the test.
    Scala unit-tests are identified by a class name regex.

    A Java test task named //path:test is internally decomposed into 2 nodes:
     - a scala_library() //path:test-lib containing the test classes;
     - and a java_binary() //path:test-bin that bundles the test classes with the JUnit runner.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of the files produced by this task,
            ie. the Java unit-test executable to run.
        test_classes: Collection of the test classes to run through the JUnit runner.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @property
    def input_fingerprint(self):
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include test sources.
        for source_wpath in self.test_sources:
            # Not really relevant right now, but will be when the content of these files are used to
            # determine the scala test classes.
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)

        # Include the test classes that need to be run.
        for test_class in self.test_classes:
            fp.add_text(test_class)

        # Include dependencies:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @base.memoized_property
    def test_sources(self):
        """Returns: workspace paths of the test source files to test."""
        sources = []
        for src_dir in self.spec.sources:
            src_dir_abs = self.tools.resolve_wpath(src_dir)
            sources.extend(self.tools.list_java_files(src_dir_abs))
            sources.extend(self.tools.list_scala_files(src_dir_abs))
        return sorted(sources)

    @base.memoized_property
    def relative_test_sources(self):
        """Returns: relative paths of the test source files to test."""
        sources = []
        for src_dir in self.spec.sources:
            src_dir_abs = self.tools.resolve_wpath(src_dir)
            source_files = itertools.chain(
                self.tools.list_java_files(src_dir_abs),
                self.tools.list_scala_files(src_dir_abs),
            )
            sources.extend(map(lambda path: os.path.relpath(path, src_dir_abs), source_files))

        return sorted(sources)

    @base.memoized_property
    def test_regexp(self):
        """Returns:
            The regular expression used to determine whether or not a scala or java file is a test.
        """
        return re.compile(self.spec.test_name_pattern)

    @base.memoized_property
    def test_classes(self):
        """Returns: A list of classes to test."""
        # Assume that each test scala file only has one test class that has the same name as the
        # file.
        test_classes = [
            os.path.splitext(source)[0].replace("/", ".")
            for source in self.relative_test_sources
            if self.test_regexp.match(os.path.splitext(os.path.basename(source))[0])
        ]
        return sorted(frozenset(test_classes))

    def run_with_io(self, output, **inputs):
        scala_test_bin = inputs["java_binary({})".format(self.name)]

        logging.debug(
            "Scala tests for %r include classes: %s",
            self.name,
            " ".join(self.test_classes)
        )

        output.output_files = scala_test_bin.output_files
        output.input_fingerprint = self.input_fingerprint
        output.test_classes = self.test_classes

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class NpmInstallTask(WorkspaceTask):
    """Incremental installation of NPM packages."""

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(self.spec.source)
        fp.add_file(self.workspace.apath(self.spec.source), missing_ok=False)
        return fp.get()

    @property
    def output_wpath(self):
        return os.path.join(
            self.workspace.wpath(self.workspace.temp_dir), "npm", self.input_fingerprint)

    @property
    def output_apath(self):
        return self.workspace.apath(self.output_wpath)

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_dir(self.output_apath)
        return fp.get()

    def run_with_io(self, output, **inputs):
        if os.path.exists(self.output_apath):
            shutil.rmtree(self.output_apath)
        base.make_dir(self.output_apath)
        shutil.copyfile(
            src=self.workspace.apath(self.spec.source),
            dst=os.path.join(self.output_apath, "package.json"),
        )

        cmd = command.Command(
            args=[self.tools.npm_path, "install"],
            work_dir=self.output_apath,
            exit_code=0,
        )
        output.spec = self.spec
        output.input_path = self.spec.source
        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.npm_install_path = self.output_wpath

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class BowerInstallTask(WorkspaceTask):
    """Incrememtal installation of bower modules."""

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()

        fp.add_text(self.spec.source)
        fp.add_file(self.tools.resolve_wpath(self.spec.source), missing_ok=False)

        # Include the dependency names and their input fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        return fp.get()

    @property
    def output_wpath(self):
        return os.path.join(
            self.workspace.wpath(self.workspace.temp_dir), "bower", self.input_fingerprint)

    @property
    def output_apath(self):
        return self.workspace.apath(self.output_wpath)

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_dir(self.workspace.apath(self.output_wpath))
        return fp.get()

    def run_with_io(self, output, **inputs):
        if os.path.exists(self.output_apath):
            shutil.rmtree(self.output_apath)
        base.make_dir(self.output_apath)
        shutil.copyfile(
            src=self.workspace.apath(self.spec.source),
            dst=os.path.join(self.output_apath, "bower.json"),
        )

        npm_installs = filter(lambda rec: rec.spec.kind == "npm_install", inputs.values())
        npm_installs = tuple(npm_installs)
        assert (len(npm_installs) == 1), \
            ("Invalid Bower configuration: require exactly one NPM install "
             "but got {}".format(len(npm_installs)))
        npm_install = npm_installs[0]
        os.symlink(
            src=os.path.join(self.workspace.apath(npm_install.npm_install_path), "node_modules"),
            dst=os.path.join(self.output_apath, "node_modules"),
        )

        cmd = command.Command(
            args=[self.tools.bower_path, "install"],
            work_dir=self.workspace.apath(self.output_wpath),
            exit_code=0,
        )
        output.spec = self.spec
        output.input_path = self.spec.source
        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.bower_install_path = self.output_wpath
        output.npm_install_path = npm_install.npm_install_path

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class JSAppTask(WorkspaceTaskForArtifact):
    """Builds a Grunt-based JavaScript application."""

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @property
    def output_wpath(self):
        path = self.name[2:].replace(":", "/")
        return os.path.join(self.workspace.wpath(self.workspace.output_dir), "bin", path)

    @property
    def output_apath(self):
        return self.workspace.apath(self.output_wpath)

    @base.memoized_property
    def sources(self):
        """Returns: workspace path of the JS application source files."""
        sources = []
        for source_spec in sorted(self.spec.sources):
            globbed = self.tools.extglob(os.path.join(source_spec.root, source_spec.selector))
            for wpath in sorted(globbed):
                sources.append((source_spec.root, os.path.relpath(wpath, source_spec.root)))
        return tuple(sources)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))
        for root_wpath, rpath in self.sources:
            source_wpath = os.path.join(root_wpath, rpath)
            source_apath = self.workspace.apath(source_wpath)
            if os.path.isfile(source_apath):
                fp.add_text(source_wpath)
                fp.add_file(source_apath, missing_ok=False)
            else:  # assume directory
                fp.add_dir(source_apath, missing_ok=False)
        return fp.get()

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()

        # Fingerrint the JS app binary folder:
        fp.add_dir(self.workspace.apath(self.output_wpath))

        # Fingerprint the JAR file:
        jar_wpath = self.tools.artifact_wpath(self.artifact)
        fp.add_text(jar_wpath)
        fp.add_file(self.tools.resolve_wpath(jar_wpath), missing_ok=True)

        # Fingerprint the POM file:
        pom_wpath = self.tools.artifact_wpath(self.artifact.update(packaging="pom"))
        fp.add_text(pom_wpath)
        fp.add_file(self.tools.resolve_wpath(pom_wpath), missing_ok=True)

        return fp.get()

    def run_with_io(self, output, **inputs):
        if os.path.exists(self.output_apath):
            shutil.rmtree(self.output_apath)
        base.make_dir(self.output_apath)

        temp_dir = os.path.join(
            self.workspace.temp_dir, self.name[2:].replace(":", "/"), self.input_fingerprint)
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        base.make_dir(temp_dir)

        bower_installs = filter(lambda rec: rec.spec.kind == "bower_install", inputs.values())
        bower_installs = tuple(bower_installs)
        assert (len(bower_installs) == 1), \
            ("Invalid JSApp configuration: require exactly one bower install "
             "but got {}".format(len(bower_installs)))
        bower_install = bower_installs[0]
        os.symlink(
            src=os.path.join(self.workspace.apath(bower_install.npm_install_path), "node_modules"),
            dst=os.path.join(temp_dir, "node_modules"),
        )
        os.symlink(
            src=os.path.join(self.workspace.apath(bower_install.npm_install_path), "package.json"),
            dst=os.path.join(temp_dir, "package.json"),
        )

        os.symlink(
            src=os.path.join(self.workspace.apath(bower_install.bower_install_path), "bower_components"),
            dst=os.path.join(temp_dir, "bower_components"),
        )
        os.symlink(
            src=os.path.join(self.workspace.apath(bower_install.bower_install_path), "bower.json"),
            dst=os.path.join(temp_dir, "bower.json"),
        )

        for root_wpath, rpath in self.sources:
            source_wpath = os.path.join(root_wpath, rpath)
            source_apath = self.workspace.apath(source_wpath)
            dest_apath = os.path.join(temp_dir, rpath)
            if os.path.isfile(source_apath):
                shutil.copyfile(src=source_apath, dst=dest_apath)
            elif os.path.isdir(source_apath):
                shutil.copytree(src=source_apath, dst=dest_apath)
            else:
                raise Error("Invalid input file: {}".format(source_apath))

        cmd = command.Command(
            args=[
                self.tools.grunt_path,
                "--gruntfile={}".format(os.path.join(temp_dir, "Gruntfile.js")),
                "build",
            ],
            work_dir=temp_dir,
            exit_code=0
        )

        # ------------------------------------------------------------
        # Repackage the JS application into output/bin:

        # Map: archive path -> workspace path
        content_map = dict()
        for js_output in self.spec.outputs:
            root_dir = os.path.join(temp_dir, js_output)
            for base_dir, dir_names, file_names in os.walk(root_dir):
                dir_names.sort()
                for file_name in sorted(file_names):
                    file_path = os.path.join(base_dir, file_name)
                    py_path = os.path.relpath(file_path, root_dir)
                    content_map[py_path] = self.workspace.wpath(file_path)

        for archive_path, file_wpath in content_map.items():
            target_path = os.path.join(self.output_apath, archive_path)
            source_path = self.workspace.apath(file_wpath)
            base.make_dir(os.path.dirname(target_path))
            shutil.copyfile(src=source_path, dst=target_path)

        # ------------------------------------------------------------
        # Expose the JS application as Python resources:

        # Base path for the JS resources (when exposed in Python/Java):
        resource_base = "webapp"

        # Map: archive path -> workspace path
        py_content_map = dict()
        py_content_map[os.path.join(resource_base, "__init__.py")] = build_tools.INIT_PY
        for archive_path, wpath in content_map.items():
            py_content_map[os.path.join(resource_base, archive_path)] = wpath

        output.python_content = py_content_map

        # ------------------------------------------------------------
        # Expose the JS application as Java resources:

        # Map: archive path -> local FS path
        java_mapping = dict()
        for archive_path, wpath in content_map.items():
            java_mapping[os.path.join(resource_base, archive_path)] = self.workspace.apath(wpath)

        with tempfile.NamedTemporaryFile(
            dir=self.workspace.temp_dir,
            prefix="javascript_library.",
            suffix=".jar",
        ) as temp_jar:
            self.tools.build_jar(
                jar_file_path=temp_jar.name,
                mapping=java_mapping,
            )
            installed_jar_path = self.tools.maven_repo_install(
                artifact=self.artifact,
                path=temp_jar.name,
            )

            pom_file_content = format_pom_file(
                artf=self.artifact,
                compile_deps=tuple(),
                exclusions=frozenset({ANY_ARTIFACT_NAME}),
                unresolved_deps=tuple(),
                fiji_build_exclusions=tuple(),
            )
            installed_pom_path = self.tools.maven_repo_install(
                artifact=self.artifact.update(packaging="pom"),
                text=pom_file_content,
            )

        # ------------------------------------------------------------

        output.spec = self.spec
        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.maven_artifacts = [self.artifact]
        output.output_files = [
            self.tools.wkspc_relpath(installed_jar_path),
            self.tools.wkspc_relpath(installed_pom_path),
        ]
        output.resolved_deps = list()

        return workflow.TaskState.SUCCESS


# --------------------------------------------------------------------------------------------------


class GeneratePomTask(WorkspaceTask):
    """Task to construct a Java library.

    This task constructs a pom from a pom template adding flattened maven dependencies in "compile"
    or "test" scope depending on whether or not they are listed in the main_deps or test_deps
    section of the spec.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        output_fingerprint: Fingerprint of the output files generated by this task.
        output_files: Collection of the files produced by this task, ie. the generated pom file.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include direct dependencies fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        # Include the fingerprint of the template pom:
        fp.add_text(self.pom_template)

        return fp.get()

    @property
    def output_fingerprint(self):
        """Returns: the fingerprint of the output of the task."""
        fp = self.tools.new_fingerprint()

        # Fingerprint the generated POM file:
        fp.add_text(self.spec.pom_file)
        fp.add_file(self.tools.resolve_wpath(self.spec.pom_file), missing_ok=True)

        return fp.get()

    @base.memoized_property
    def pom_template(self):
        # Load the pom template.
        if self.spec.pom_template is not None:
            resolved_pom_template = self.tools.resolve_wpath(self.spec.pom_template)
            assert os.path.exists(resolved_pom_template), \
                "Unable to locate pom file {!s}".format(resolved_pom_template)
            with open(resolved_pom_template, mode="rt", encoding="UTF-8") as f:
                return f.read()
        else:
            return POM_XML_TEMPLATE

    def should_task_run(self, task_run_id, output, **inputs):
        should_run = (output.output_fingerprint != self.output_fingerprint)
        if should_run:
            logging.debug("Processing task %r : output %r != expected output %r",
                          self.task_id, self.output_fingerprint, output.output_fingerprint)
        else:
            logging.debug("Skipping task %r", self.task_id)
        return should_run

    def run_with_io(self, output, **inputs):
        logging.debug(
            "Generating pom file in %r from template %r",
            self.spec.pom_file,
            self.spec.pom_template
        )

        # Assemble the main_deps classpath:
        (main_build_deps, main_declared_deps, main_exclusions, dynamic_deps, provided_slots) = \
            self.tools.get_java_deps(
                spec_name=self.spec.name,
                deps=self.spec.main_deps,
                maven_exclusions=self.spec.get("main_maven_exclusions", tuple()),
                provided_slots=tuple(),
                inputs=inputs,
                workflow=self.workflow
            )
        main_maven_deps = self.tools.resolve_deps(
            artifacts=main_build_deps,
            exclusions=main_exclusions,
            scope="compile",
        )
        main_maven_deps = sorted(main_maven_deps)

        # Assemble the test_deps classpath:
        (test_build_deps, test_declared_deps, test_exclusions, dynamic_deps, provided_slots) = \
            self.tools.get_java_deps(
                spec_name=self.spec.name,
                deps=self.spec.test_deps,
                maven_exclusions=self.spec.get("test_maven_exclusions", tuple()),
                provided_slots=tuple(),
                inputs=inputs,
                workflow=self.workflow
            )
        test_maven_deps = self.tools.resolve_deps(
            artifacts=test_build_deps,
            exclusions=test_exclusions,
            scope="test",
        )
        test_maven_deps = sorted(test_maven_deps)

        # Assemble a list of the direct dependencies' names:
        pom_deps = [artf.name for artf in main_declared_deps + test_declared_deps]

        # Infer a version for the generated pom and get a list of the direct dependencies names.
        version = None
        for dep_name in itertools.chain(self.spec.main_deps, self.spec.test_deps):
            for dep_artifact in self.input[dep_name].maven_artifacts:
                if version is not None and dep_artifact.version != version:
                    raise Error("The artifacts that this pom depends on have different versions!")
                else:
                    version = dep_artifact.version

        if version is None:
            # Defaults to the version ID configured for Maven artifacts:
            version = self.workspace.config.maven_artifact_version

        # Setup the artifact that the pom file will represent.
        aname = artifact_from_name(self.spec.pom_name)
        pom_artifact = artifact.Artifact(
            group_id=aname.group_id,
            artifact_id=aname.artifact_id,
            version=version,
        )

        # Remove dependencies already a part of the pom dependencies. This is not a generator since
        # it gets used twice.
        main_maven_deps_cleaned = [dep for dep in main_maven_deps if dep.name not in pom_deps]
        main_maven_dep_names = [(dep.name, dep.packaging) for dep in main_maven_deps_cleaned]

        # Remove test and pom dependencies that are already in main dependencies.
        test_maven_deps_cleaned = (
            dep
            for dep in test_maven_deps
            # This gives precedence to dependencies that are in compile scope (over test-scope)
            if (dep.name, dep.packaging) not in main_maven_dep_names and dep.name not in pom_deps
        )

        # Generate the pom.xml file.
        pom_file_content = format_pom_file(
            artf=pom_artifact,
            compile_deps=sorted(main_maven_deps_cleaned),
            test_deps=sorted(test_maven_deps_cleaned),
            exclusions=frozenset({ANY_ARTIFACT_NAME}),
            pom_template=self.pom_template,
        )
        generated_pom_path = self.tools.resolve_wpath(self.spec.pom_file)
        with open(generated_pom_path, mode="wt", encoding="UTF-8") as f:
            f.write(pom_file_content)

        # This is a leaf node and these probably shouldn't get used.
        output.input_fingerprint = self.input_fingerprint
        output.output_fingerprint = self.output_fingerprint
        output.output_files = [self.spec.generated_pom]

        return workflow.TaskState.SUCCESS

    @property
    def graphviz_label(self):
        return "\\n".join(["Generate maven pom", self.name])


# --------------------------------------------------------------------------------------------------


class RunCheckstyleTask(WorkspaceTask):
    """Task to run checkstyle on a Java library or test.

    This task runs checkstyle by downloading the checkstyle jar from maven and running it.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        checkstyle_config: CheckstyleConfig record defining the details for running checkstyle used
            by this task.
        checkstyle_output: String stdout from running checkstyle.
        checkstyle_error: String stderr from running checkstyle.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def java_sources(self):
        """Returns: workspace path of the Java source files to compile."""
        sources = []
        for src_dir in self.spec.sources:
            sources.extend(self.tools.glob(os.path.join(src_dir, "**.java")))
        return sorted(sources)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include direct dependencies fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        for source_wpath in self.java_sources:
            fp.add_text(source_wpath)
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)

        # Include the fingerprint of the checkstyle.xml file:
        fp.add_file(self.tools.resolve_wpath(self.spec.checkstyle_config.config))

        # Include the fingerprint of the suppressions.xml file:
        if self.spec.checkstyle_config.suppressions is not None:
            fp.add_file(self.tools.resolve_wpath(self.spec.checkstyle_config.suppressions))

        # Include the fingerprint of the header file:
        if self.spec.checkstyle_config.header is not None:
            fp.add_file(self.tools.resolve_wpath(self.spec.checkstyle_config.header))

        return fp.get()

    def run_with_io(self, output, **inputs):
        # TODO: Should this be an error?
        if len(self.java_sources) == 0:
            logging.debug(
                "Skipping run checkstyle task %s because there are no sources.",
                self.name,
            )
            return workflow.TaskState.SUCCESS

        logging.debug("Running checkstyle using %r", self.spec.checkstyle_config)

        # Assemble the classpath for running checkstyle (so checkstyle can find classes referenced
        # in javadoc comments and exceptions being thrown):
        (build_deps, declared_deps, exclusions, dynamic_deps, provided_slots) = \
            self.tools.get_java_deps(
                spec_name=self.spec.name,
                deps=self.spec.deps,
                maven_exclusions=tuple(),
                provided_slots=tuple(),
                inputs=inputs,
                workflow=self.workflow
            )
        resolved_build_deps = self.tools.resolve_deps(
            artifacts=build_deps,
            exclusions=exclusions,
            scope="compile",
        )
        resolved_build_deps = sorted(resolved_build_deps)
        logging.debug("Resolved build dependencies for run checkstyle task %r:\n%s",
                      self.name, "\n".join(map(lambda x: "\t" + str(x), resolved_build_deps)))

        build_classpath = map(self.tools.resolve_maven_artifact, resolved_build_deps)
        build_classpath = sorted(build_classpath)

        # Run checkstyle itself.
        run_checkstyle = self.tools.run_checkstyle(
            build_classpath=build_classpath,
            config_path=self.spec.checkstyle_config.config,
            sources=self.java_sources,
            suppressions_path=self.spec.checkstyle_config.suppressions,
            header_path=self.spec.checkstyle_config.header,
        )

        # This is a leaf node and these probably shouldn't get used.
        output.input_fingerprint = self.input_fingerprint
        output.checkstyle_config = self.spec.checkstyle_config
        output.checkstyle_output = run_checkstyle.output_text
        output.checkstyle_error = run_checkstyle.error_text

        if run_checkstyle.exit_code == 0:
            logging.debug("Run checkstyle output for %r: %s",
                          self.name, format_command_output(run_checkstyle))
            return workflow.TaskState.SUCCESS
        else:
            logging.info("Run checkstyle output for %r: %s",
                         self.name, format_command_output(run_checkstyle))
            return workflow.TaskState.FAILURE

    @property
    def graphviz_label(self):
        return "\\n".join(["Run checkstyle", self.name])


# --------------------------------------------------------------------------------------------------


class RunScalastyleTask(WorkspaceTask):
    """Task to run scalastyle on a Scala library/test.

    This task runs scalastyle by downloading the scalastyle jar from maven and running it.

    Output:
        input_fingerprint: Fingerprint of the input files consumed processed by this task.
        scalastyle_config: Path to the scalastyle config file used by this task.
        scalastyle_output: String stdout from running scalastyle.
        scalastyle_error: String stderr from running scalastyle.
    """

    def get_task_run_id(self):
        return "%s.fp=%s" % (self.task_id, self.input_fingerprint)

    @base.memoized_property
    def scala_sources(self):
        """Returns: workspace path of the Java source files to compile."""
        sources = []
        for src_dir in self.spec.sources:
            sources.extend(self.tools.glob(os.path.join(src_dir, "**.scala")))
        return sorted(sources)

    @base.memoized_property
    def input_fingerprint(self):
        """Returns: the fingerprint of the input of the task."""
        fp = self.tools.new_fingerprint()
        fp.add_text(str(self.spec))

        # Include direct dependencies fingerprints:
        for dep_name, dep_input in sorted(self.input._params.items()):
            fp.add_text(dep_name)
            fp.add_text(dep_input.input_fingerprint)

        for source_wpath in self.scala_sources:
            fp.add_text(source_wpath)
            fp.add_file(self.tools.resolve_wpath(source_wpath), missing_ok=False)

        # Include the fingerprint of the scalastyle config file:
        fp.add_file(self.tools.resolve_wpath(self.spec.scalastyle_config))

        return fp.get()

    def run_with_io(self, output, **inputs):
        # TODO: Should this be an error?
        if len(self.scala_sources) == 0:
            logging.debug(
                "Skipping run scalastyle task %s because there are no sources.",
                self.name,
            )
            return workflow.TaskState.SUCCESS

        logging.debug("Running scalastyle using %r", self.spec.scalastyle_config)

        # Run scalastyle itself.
        run_scalastyle = self.tools.run_scalastyle(
            config_path=self.spec.scalastyle_config,
            sources=self.scala_sources,
        )

        # This is a leaf node and these probably shouldn't get used.
        output.input_fingerprint = self.input_fingerprint
        output.scalastyle_config = self.spec.scalastyle_config
        output.scalastyle_output = run_scalastyle.output_text
        output.scalastyle_error = run_scalastyle.error_text

        if run_scalastyle.exit_code == 0:
            logging.debug("Run scalastyle output for %r: %s",
                          self.name, format_command_output(run_scalastyle))
            return workflow.TaskState.SUCCESS
        else:
            logging.info("Run scalastyle output for %r: %s",
                         self.name, format_command_output(run_scalastyle))
            return workflow.TaskState.FAILURE


    @property
    def graphviz_label(self):
        return "\\n".join(["Run scalastyle", self.name])


# --------------------------------------------------------------------------------------------------


if __name__ == "__main__":
    raise Exception("Not a standalone module.")
